{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankings\n",
    "#### Aquesta setmana hem aconseguit executar l'script de rankings en el jupyter, per aconseguir-ho hem fet:\n",
    "####     -Crear el notebook al jupyter.\n",
    "####     -Guardar.\n",
    "####     -Obrir amb el Canopy, llavors s'obrirà el notebook al jupyter.\n",
    "####     -Executar (perque fent aquests pasos utilizta les llibreries del Canopy).\n",
    "\n",
    "#### Comencem fent els import basics, incluint el params (inclou la direcció dels arxius)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of clusters:', 1024)\n",
      "('Descriptor type:', 'SIFT')\n",
      "('Keypoint detector:', 'SIFT')\n",
      "('Resize dimension:', 300)\n",
      "('Distance metric:', 'euclidean')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "#import sys\n",
    "# Add the root path (the path above this one) to the pythonpath.\n",
    "# sys.path.insert(0,../)\n",
    "from params import get_params\n",
    "\n",
    "params = get_params()\n",
    "\n",
    "print (\"Number of clusters:\", params['descriptor_size'])\n",
    "print (\"Descriptor type:\",params['descriptor_type'])\n",
    "print (\"Keypoint detector:\", params['keypoint_type'])\n",
    "print (\"Resize dimension:\", params['max_size'])\n",
    "print (\"Distance metric:\", params['distance_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction with Bag of Words\n",
    "\n",
    "#### Utilitzem la funció get_features per calcular els descriptors locals de totes les imatges d'entrenament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done. Time elapsed:', 127.92300009727478)\n",
      "(216506L, 128L)\n"
     ]
    }
   ],
   "source": [
    "import get_features as GF\n",
    "# Make sure that we are using training images only !\n",
    "params['split'] = 'train'\n",
    "\n",
    "t = time.time()\n",
    "X, pca, scaler = GF.stack_features(params)\n",
    "\n",
    "print (\"Done. Time elapsed:\", time.time() - t)\n",
    "print (np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despres d'acabar amb l'entrenament de features podem començar a entrenar el nostre codebook. Utilitzem MiniBatchKMeans perque es molt mes ràpid que el KMeans normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done. Time elapsed:', 27.914000034332275)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "GF.train_codebook(params,X)\n",
    "\n",
    "print (\"Done. Time elapsed:\", time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Una vegada tenim el codebook, podem fer les asignacions a cada imatge i fer el Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done. Time elapsed for training set:', 120.07500004768372)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "GF.get_features(params)\n",
    "\n",
    "print (\"Done. Time elapsed for training set:\", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done. Time elapsed for validation set:', 46.930999994277954)\n"
     ]
    }
   ],
   "source": [
    "# Switch to validation set\n",
    "params['split'] = 'val'\n",
    "\n",
    "t = time.time()\n",
    "# Run again\n",
    "GF.get_features(params)\n",
    "\n",
    "print (\"Done. Time elapsed for validation set:\", time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generem el ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done. Time elapsed:', 1.194000005722046)\n"
     ]
    }
   ],
   "source": [
    "from rank import *\n",
    "\n",
    "t = time.time()\n",
    "rank(params)\n",
    "\n",
    "print (\"Done. Time elapsed:\", time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of queries:', 120)\n",
      "('Mean Average Precision', 0.24347167699973812)\n"
     ]
    }
   ],
   "source": [
    "import eval_rankings as ER\n",
    "\n",
    "ap_list, dict_ = ER.eval_rankings(params)\n",
    "\n",
    "print (\"Number of queries:\", len(ap_list))\n",
    "print (\"Mean Average Precision\", np.mean(ap_list)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercat_independencia 0.13933528359\n",
      "societat_general 0.241627870337\n",
      "farmacia_albinyana 0.377998333511\n",
      "ajuntament 0.759791571174\n",
      "mnactec 0.168620482365\n",
      "escola_enginyeria 0.206969113069\n",
      "masia_freixa 0.0951695608574\n",
      "castell_cartoixa 0.182445905157\n",
      "dona_treballadora 0.0866802743736\n",
      "catedral 0.191894538954\n",
      "teatre_principal 0.366097426245\n",
      "estacio_nord 0.105029764362\n"
     ]
    }
   ],
   "source": [
    "for id in dict_.keys():\n",
    "    \n",
    "    if not id == 'desconegut':\n",
    "        # We divide by 10 because it's the number of images per class in the validation set.\n",
    "        print id, dict_[id]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escola_enginyeria\n",
      "450\n",
      "Displaying...\n"
     ]
    }
   ],
   "source": [
    "query_id = '11962-11431-11239'\n",
    "ER.single_eval(params,query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hem aconseguit un MAP d'uns 0'24, encara que va variant cada vegada que s'executa. I no hem aconseguit que fes Display dins del jupyter, s'obre una finestra."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
